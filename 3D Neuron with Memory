import numpy as np
from scipy.special import sph_harm

class Neuron:
    def __init__(self, position):
        self.weights = {
            'x_input': None,
            'y_input': None,
            'z_input': None,
            'lifelong_learning': None,
            'meta_awareness': None
        }
        self.bias = 0
        self.type = None
        self.position = position

    def set_type(self, direction):
        if direction == 'X':
            self.type = 'input'
        elif direction == 'Y':
            self.type = 'hidden'
        elif direction == 'Z':
            self.type = 'output'
        else:
            raise ValueError("Invalid direction")

    def init_weights(self, l2_norm=1.0):
        # Initialize weights using spherical harmonics to account for 3D position
        l, m = divmod(self.position[0], 2)
        if m > 0:
            l += 1

        self.weights['x_input'] = sph_harm(m, l, np.pi * self.position[1] / (2 ** self.position[0]), 2 * np.pi * self.position[2]).real
        self.weights['y_input'] = sph_harm(-m, l, 2 * np.pi * self.position[1], np.pi * self.position[0] / (2 ** self.position[2])).real
        self.weights['z_input'] = sph_harm(m, l - abs(m), 2 * np.pi * self.position[1], np.pi * self.position[2]).real

        # Normalize weights to have unit L2 norm
        for w in self.weights.values():
            if w is not None:
                w /= np.linalg.norm(w)

    def set_weights(self, lifelong_learning, meta_awareness):
        self.weights['lifelong_learning'] = lifelong_learning
        self.weights['meta_awareness'] = meta_awareness

    def process_input(self, input_value):
        if self.type == 'input':
            weighted_sum = np.dot(input_value, [self.weights['x_input'], self.weights['y_input'], self.weights['z_input']])
        elif self.type in ['hidden', 'output']:
            weighted_sum = 0
            for i, weight in enumerate(self.weights.values()):
                if weight is not None:
                    weighted_sum += np.dot(input_value[i], weight)
        else:
            raise ValueError("Invalid neuron type")

        # Adding bias and applying activation function (e.g., sigmoid)
        output = self.sigmoid(weighted_sum + self.bias)

        return output

    @staticmethod
    def sigmoid(x):
        return 1 / (1 + np.exp(-x))
